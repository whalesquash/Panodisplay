{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting loop.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile loop.pyx\n",
    "\n",
    "###cython: boundscheck=False, wraparound=False, nonecheck=False\n",
    "#%%cython --annotate\n",
    "\n",
    "#First comment are compiler directives.\n",
    "\n",
    "#This cython implementation massively speeds up the loop in imageDeform\n",
    "#...at the cost of conciseness, see below for slower, easier to understand version of imageDeform\n",
    "\n",
    "from cython.parallel import prange\n",
    "\n",
    "cpdef loop(short[:,::1] x,float[:,::1] xmap,float[:,::1] ymap, int w, int h, int wT):\n",
    "    cdef:\n",
    "        Py_ssize_t j\n",
    "        Py_ssize_t i\n",
    "        Py_ssize_t i2\n",
    "        Py_ssize_t l\n",
    "        short start\n",
    "        short stop\n",
    "        \n",
    "        short flagSecondInterval = False\n",
    "        short start2 = 0\n",
    "        short stop2\n",
    "        \n",
    "        short tmp = 2*wT\n",
    "    for j in range(h):\n",
    "        for i in range(w): \n",
    "            if x[j,i] == 0: #limit condition\n",
    "                i2 = i -1\n",
    "                start = x[j,i2] #negative\n",
    "                stop = tmp\n",
    "                start = tmp + start\n",
    "                for l in range(start,stop):\n",
    "                    xmap[j, l] = i \n",
    "                    ymap[j, l] = j\n",
    "            else:\n",
    "                if i != 0:\n",
    "                    i2 = i -1\n",
    "                    start = x[j,i2]\n",
    "                    stop = x[j,i]\n",
    "                    \n",
    "                    if start < 0: #if start negative stop needs to be negative, if it is not we need a second interval\n",
    "                        #to cover the central part of the image and avoid a black vertical line\n",
    "                        start = tmp + start\n",
    "                        if stop <= 0:\n",
    "                            stop =  tmp + stop\n",
    "                        else:\n",
    "                            flagSecondInterval = True\n",
    "                            stop2 = stop\n",
    "                            stop = tmp\n",
    "\n",
    "                    for l in range(start, stop):\n",
    "                        xmap[j, l] = i\n",
    "                        ymap[j, l] = j\n",
    "                        \n",
    "                    if flagSecondInterval:\n",
    "                        for l in range(start2, stop2):\n",
    "                            xmap[j, l] = i\n",
    "                            ymap[j, l] = j\n",
    "                        flagSecondInterval = False\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%writefile PanoImage.py\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, pi\n",
    "import cv2\n",
    "from time import time\n",
    "from loop import loop\n",
    "\n",
    "class PanoImage:\n",
    "    '''\n",
    "    PanoImage class\n",
    "    \n",
    "    Description:\n",
    "        Short: Allows to create images suitable for the PanoDisplay\n",
    "        Long: - checks that the canvas (output image) has a 2:1 aspect ratio, \n",
    "              - allows to place images on the canvas according to angular position,\n",
    "              - allows to straighten the images so they do not look deformed/smaller near the poles,\n",
    "              - allows access to image's pixel value and angular position via getImage() and getAngleMatrix(), or __get__\n",
    "    \n",
    "    Possible Todos: - could eventually allow other coordinate systems than spheric.\n",
    "    \n",
    "    Inputs: - Image (PIL or numpy array), so typically 2D array with 3 channels (RGB), example shape=(794,894,3)\n",
    "            - angular position [lon, lat] in degrees\n",
    "            - angular matrix if angular position not given, same size as image but angular positions for each pixel\n",
    "              instead of RGB values.\n",
    "            - coordinate system, only 'spheric' for now, eventually more later\n",
    "            - resolution [width, height] in pixels, for a 'spheric' coordinate system the aspect ratio must be 2:1\n",
    "            \n",
    "    Outputs:- Instance of the PanoImage class via constructor and compress/stretch.\n",
    "            - np.array via methods getArray() and getAngleMatrix()\n",
    "            - matplotlib plot with show()\n",
    "            \n",
    "    Example:\n",
    "                filename = 'res/test_panodisplay'\n",
    "                im = Image.open(filename + '.png')\n",
    "                im = im.resize([2048,1024], Image.BILINEAR)\n",
    "                a = PanoImage(im).stretch()\n",
    "                a.show()\n",
    "                b = a.getArray()\n",
    "                im = Image.fromarray(b)\n",
    "                im.save(filename + '_stretched.png')\n",
    "\n",
    "    '''\n",
    "    WIDTH = 500\n",
    "    HEIGHT = 250 \n",
    "    \n",
    "    def __init__(self, im = None, units = 'deg', pos_angles = None, \n",
    "                 size = None, background = None, res = (WIDTH,HEIGHT)):\n",
    "        '''\n",
    "        image can be either PIL 'image' (it is transformed in np.array) or numpy array\n",
    "        units 'pix' or 'deg' for size parameter\n",
    "        needs pos (longitude, latitude) always in degrees\n",
    "        size = (x,y)\n",
    "        #since the visual angles are defined independently from a referential\n",
    "        #coordinate system the size is set from the center of the equator\n",
    "        #NB: to get the correct size/aspect ratio all over the screen use stretch()\n",
    "        you can set a different background (same format as image, but dimensions of res)\n",
    "        res (width, height) always in pixels   \n",
    "        '''\n",
    "        self.BG_COLOR = 0\n",
    "        \n",
    "        if im is None:\n",
    "            print('Info: no array given, loading dummy as array.')\n",
    "            self.im = self._loadDummy()\n",
    "        elif type(im) is np.ndarray:\n",
    "            if im.dtype == 'uint8':\n",
    "                self.im = im\n",
    "            else:\n",
    "                self.im = np.uint8(im)\n",
    "        else:\n",
    "            self.im = np.asarray(im,dtype=np.uint8)\n",
    "            if len(self.im.shape) == 3:\n",
    "                if self.im.shape[2] > 3:\n",
    "                    self.im = self.im[:,:,:3]\n",
    "        self.base_im = np.array(self.im)\n",
    "        \n",
    "        if units in ('pix', 'deg'):\n",
    "            self.units = units\n",
    "        else:\n",
    "            self.units = 'pix'\n",
    "            print('Unknown units -> set to pixels.')\n",
    "            \n",
    "        if(res[0] == 2*res[1]):\n",
    "            self.res = res\n",
    "        else:\n",
    "            self.res = [2*res[1],res[1]]\n",
    "            print('Warning: in a spheric coordinate system, the resolution must have a 2:1 aspect ratio: x-coordinate recalculated to fit that requirement: resolution is {0}'.format(self.res))\n",
    "        \n",
    "        if background is None:\n",
    "            self.background = np.full([self.res[1],self.res[0],3], self.BG_COLOR, dtype = np.uint8)\n",
    "        else:\n",
    "            self.background = background\n",
    "\n",
    "        if pos_angles is None:\n",
    "            self.pos_angles = [0,0]  \n",
    "        else:\n",
    "            self.pos_angles = pos_angles\n",
    "                \n",
    "        if size is not None:\n",
    "            if self.units == 'pix':\n",
    "                self.im = cv2.resize(self.im, size)\n",
    "            elif self.units == 'deg':\n",
    "                x_start, x_end = self._lon2x(-size[0]/2, res[0]), self._lon2x(size[0]/2, res[0])\n",
    "                y_start, y_end = self._lat2y(-size[1]/2, res[1]), self._lat2y(size[1]/2, res[1])\n",
    "                x, y = x_end - x_start, y_end - y_start\n",
    "#                 TODO: check that resizing does not unbalance the picture on one side (even -> uneven)\n",
    "#                 if x%2==1:\n",
    "#                     x += 1\n",
    "                self.im = cv2.resize(self.im, (x,y))\n",
    "            \n",
    "    def _loadDummy(self):\n",
    "        '''\n",
    "        Loads the dummy image in the res folder, then returns it as a numpy array.\n",
    "        '''\n",
    "        im = Image.open('res/cat.png')\n",
    "        arr = np.asarray(im)[:,:,:3]\n",
    "        return arr\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.base_im[key[0],key[1]], self.getAngleMatrix()[key[0],key[1]]\n",
    "    \n",
    "    def getImage(self):\n",
    "        return self.base_im\n",
    "\n",
    "    def _lon2x(self, lon, tex_width):\n",
    "        return int(float(lon+180) /180. * tex_width/2.)\n",
    "    def _lat2y(self, lat, tex_height):\n",
    "        return int(float(lat+90) /90. * tex_height/2.)\n",
    "    def _angles2pix(self, angles, tex_dim):\n",
    "        return (self._lon2x(angles[0], tex_dim[0]),\n",
    "            self._lat2y(angles[1], tex_dim[1]))\n",
    "    \n",
    "    def _x2lon(self,x, tex_width):\n",
    "        return float(x - tex_width/2)/tex_width *360. \n",
    "    def _y2lat(self,y, tex_height):\n",
    "        return float(y - tex_height/2)/tex_height *180. \n",
    "    def _pix2angles(self,pix, tex_dim):\n",
    "        if type(pix) == list or (len(pix.shape) == 1 and pix.shape[0] == 2):\n",
    "            return (self._x2lon(pix[0], tex_dim[0]),\n",
    "                self._y2lat(pix[1], tex_dim[1]))\n",
    "        else:\n",
    "            vec_x2lon = np.vectorize(self._x2lon)\n",
    "            vec_y2lat = np.vectorize(self._y2lat)\n",
    "            result = np.zeros(pix.shape)\n",
    "            result[:,:,0] = vec_x2lon(pix[:,:,0], tex_dim[0])\n",
    "            result[:,:,1] = vec_y2lat(pix[:,:,1], tex_dim[1])\n",
    "            return result\n",
    "\n",
    "    def _broadcastRegions(self):\n",
    "        '''\n",
    "        The rectangle intersection function takes the Bottom-Left and Top-Right corners\n",
    "        of two rectangles and returns the Bottom-Left and Top-Right corners of the intersection\n",
    "        rectangle, or None if they dont intersect.\n",
    "        Here we need to order the values correctly, because y-axis is inverted.'''\n",
    "        tex = self.background\n",
    "        tex_xBL, tex_yBL = 0, 0\n",
    "        tex_xTR, tex_yTR = tex.shape[1], tex.shape[0]\n",
    "        \n",
    "        im = self.im\n",
    "        w, h = im.shape[1], im.shape[0]\n",
    "        pos_im = self._angles2pix(self.pos_angles, self.res)\n",
    "        \n",
    "        #Take into account the even/odd number of pixels\n",
    "        if w%2 == 0:\n",
    "            im_xBL = pos_im[0]-int(w/2)\n",
    "        else:\n",
    "            im_xBL = pos_im[0]-int((w+1)/2)\n",
    "        im_xTR = pos_im[0]+int(w/2)\n",
    "            \n",
    "        if h%2 ==0:\n",
    "            im_yBL = pos_im[1]-int(h/2)\n",
    "        else:\n",
    "            im_yBL = pos_im[1]-int((h+1)/2)\n",
    "        im_yTR = pos_im[1]+int(h/2)\n",
    "\n",
    "        #Limit conditions for broadcasting\n",
    "        if self.intersectRectangles(im_xBL, im_yBL, im_xTR, im_yTR, \n",
    "                                          tex_xBL, tex_yBL, tex_xTR, tex_yTR) is not None:\n",
    "            x1,y1,x2,y2 = self.intersectRectangles(im_xBL, im_yBL, im_xTR, im_yTR, \n",
    "                                              tex_xBL, tex_yBL, tex_xTR, tex_yTR)\n",
    "        else:\n",
    "            raise('The stimulus is completely outside the frame.')\n",
    "            \n",
    "        left, bot, right, top = int(x1), int(y1), int(x2), int(y2)\n",
    "        im_left, im_right = left - im_xBL, right - im_xBL\n",
    "        im_bot, im_top = bot - im_yBL, top - im_yBL\n",
    "        \n",
    "        return top, bot, left, right, im_top, im_bot, im_left, im_right\n",
    "    \n",
    "    def apply(self, mask = False):\n",
    "        '''Applies the image on the background and returns the resulting image.\n",
    "        The optional mask parameter allows to set the pixels thrown outside the screen\n",
    "        to a value, so a photodiode (placed on the fisheye) can witness the presence\n",
    "        of the stimulus.'''\n",
    "        tex = self.background\n",
    "        im = self.im\n",
    "        \n",
    "        top, bot, left, right, im_top, im_bot, im_left, im_right = self._broadcastRegions()\n",
    "        tex[top: bot, left: right] = im[im_top: im_bot, im_left:im_right]\n",
    "        \n",
    "        if mask:\n",
    "            lon_limit = 145\n",
    "            x1_limit = self._lon2x(lon_limit, tex.shape[1])\n",
    "            x2_limit = self._lon2x(-lon_limit, tex.shape[1])\n",
    "            lat_limit = 80\n",
    "            y_limit = self._lat2y(lat_limit, tex.shape[0])\n",
    "            tex[int(tex.shape[0]/2):,:x2_limit] = \\\n",
    "                tex[int(tex.shape[0]/2):,x1_limit:] = \\\n",
    "                tex[y_limit:,:] = 255\n",
    "        return tex\n",
    "        \n",
    "    def getAngleMatrix(self):\n",
    "        '''\n",
    "        Returns a numpy array of lists of tuples.\n",
    "        Each sublist is a row (longitude), each tuple represents a (longitude, latitude).\n",
    "        This 'matrix' has the same dimensions as the numpy array holding the image (getArray()), \n",
    "        so you can access each pixel per index.'''\n",
    "        top, bot, left, right, _, _, _, _ = self._broadcastRegions()\n",
    "        xy_mat = np.array([[(i,j) for i in range(left, right,1) ] for j in range(top, bot, 1)])\n",
    "        return self._pix2angles(xy_mat, self.res)\n",
    "    \n",
    "    def _scalingFactor(self, latitude):\n",
    "        '''Takes latitude in degrees and outputs the corresponding scaling factor'''\n",
    "        return 1./cos(1.*latitude/180. *pi)\n",
    "        \n",
    "    def _cropImage(self,im):\n",
    "        '''Allows to crop the image.\n",
    "        Useful if there are multiple stimuli presented on the same background.\n",
    "        Should be redone with transparency filter instead: currently the crop is rectangular, which can suck\n",
    "        if the stimuli are intersecting.'''\n",
    "        im_copy = np.array(im,dtype=np.uint8)\n",
    "        im_copy = np.where(im_copy == self.BG_COLOR, 0, im_copy)\n",
    "        \n",
    "        gray = cv2.cvtColor(im_copy, cv2.COLOR_BGR2GRAY)\n",
    "        th, threshed = cv2.threshold(gray, 254, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "        morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        return im[y:y+h, x:x+w]\n",
    "    \n",
    "    def _imageDeform(self, compress = False):\n",
    "        '''\n",
    "        Performs compression or stretching (default) on the image to apply,\n",
    "        not on the full (2:1 AR) texture.\n",
    "        For each pixel of the destination image, finds the corresponding pixel \n",
    "        in the source image. Uses interpolation.\n",
    "        '''\n",
    "        \n",
    "        im = self.im\n",
    "\n",
    "        #Get image borders\n",
    "        top, bot, left, right, im_top, im_bot, im_left, im_right = self._broadcastRegions()\n",
    "        im = im[im_top: im_bot, :]\n",
    "        \n",
    "        w, h = im.shape[1], im.shape[0]\n",
    "        \n",
    "        #Get individual y coordinates\n",
    "        y = np.arange(top,bot)\n",
    "        tex = self.background\n",
    "        \n",
    "        #Get vector containing scaling factors for each elevation\n",
    "        vec_y2lat = np.vectorize(self._y2lat)\n",
    "        vec_scale = np.vectorize(self._scalingFactor)\n",
    "        to_lat = vec_y2lat(y,self.res[1])\n",
    "        s = vec_scale(to_lat)\n",
    "        s = s.reshape(s.shape[0],1)\n",
    "        \n",
    "        #Reverse if specified\n",
    "        if compress:\n",
    "            s = 1./s\n",
    "        \n",
    "        #Get vector containing (h*) lines with x values\n",
    "        t2 = np.array(([np.arange(w) - float(w)/2] * y.shape[0]))\n",
    "        \n",
    "        #Multiply scaling factors with x coordinates\n",
    "        tmp = np.float32(np.multiply(t2,s))\n",
    "        \n",
    "        #Restrict to 16 bits precision and convert\n",
    "        tmp[(tmp>32767)] = 32767\n",
    "        tmp[(tmp<-32768)] = -32768\n",
    "        x = np.array(tmp, dtype = np.int16)\n",
    "        \n",
    "        #Restrict to the area we can effectively cover to reduce computing time\n",
    "        wT = tex.shape[1]\n",
    "        x[(x <= -wT)] = -wT\n",
    "        x[(x >= wT)] = wT-1\n",
    "\n",
    "        #Initialize maps\n",
    "        xmap = np.full((h,wT*2),w+1, np.float32)\n",
    "        ymap = np.zeros((h,wT*2), np.float32)\n",
    "        \n",
    "        #Update maps - wrote loop with Cython\n",
    "        loop(x,xmap,ymap,w,h, wT)\n",
    "        \n",
    "        #Resize the original image: the remap function can only remap pixels from and to the original image\n",
    "        #so we place it on a larger background\n",
    "        resized_im = np.full((h,wT*2,3), self.BG_COLOR, dtype=np.float32)\n",
    "        resized_im[:, : im.shape[1]] = im\n",
    "        \n",
    "        #So far the maps were symmetric around 0, we change that for the remap function\n",
    "        xmap = np.hstack((xmap[:,-wT:], xmap[:,:wT]))\n",
    "        ymap = np.hstack((ymap[:,-wT:], ymap[:,:wT]))\n",
    "        \n",
    "        #CV2 remap\n",
    "        remapped_im = cv2.remap(resized_im, xmap, ymap, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "        \n",
    "        #We rectangularly crop the image by detecting the background-foreground elements and removing background\n",
    "        #cropped_im = self._cropImage(remapped_im)\n",
    "        \n",
    "        #Get new image position on canvas, necessary if parts of the image are outside the frame\n",
    "        new_pos_pix_y = np.array([int((bot+top)/2)])\n",
    "        new_pos_angles_y = self._y2lat(new_pos_pix_y, self.res[1])\n",
    "        \n",
    "        return PanoImage(remapped_im, units=self.units, background = self.background,pos_angles=(self.pos_angles[0],new_pos_angles_y))\n",
    "    \n",
    "    def compress(self):\n",
    "        return self._imageDeform(compress = True)\n",
    "    def stretch(self):\n",
    "        return self._imageDeform()\n",
    "    \n",
    "    def toPano(self, xmap, ymap,  h = 720, size = None):\n",
    "        '''Maps a panoimage (2D image with 2:1 aspect ratio) to the dome.\n",
    "        The xmap and ymap need to be generated with the PanoDisplay generateMappingData function\n",
    "        for every different position of the projector-optical bloc setup.'''\n",
    "        im = self.apply()\n",
    "        im = cv2.flip(im, 1)\n",
    "        #im = np.hstack((im[:,-int(im.shape[1]/2):], im[:,:int(im.shape[1]/2)]))\n",
    "        if size is not None:\n",
    "            im = cv2.resize(im,size)\n",
    "        else:\n",
    "            im = cv2.resize(im,(500,250))\n",
    "        im = np.float32(im)/255\n",
    "        resized_im = np.full((2048,2048,3), self.BG_COLOR, dtype=np.float32)\n",
    "        resized_im[:im.shape[0], : im.shape[1]] = im\n",
    "\n",
    "        new_im = cv2.remap(resized_im, xmap, ymap,cv2.INTER_LINEAR, None,cv2.BORDER_REPLICATE)\n",
    "        new_im = cv2.resize(new_im,(h,h))\n",
    "\n",
    "        #pano_im = np.full((h,w,3), self.BG_COLOR, dtype=np.float32)\n",
    "        #pano_im[:new_im.shape[0], 240: new_im.shape[1]+240] = new_im\n",
    "        return new_im\n",
    "        \n",
    "    def intersectRectangles(self,x1, y1, x2, y2, x3, y3, x4, y4):\n",
    "        '''Get the intersection points of two intersecting rectangles.'''\n",
    "        # gives bottom-left point of intersection rectangle \n",
    "        x5, y5 = max(x1, x3), max(y1, y3)\n",
    "        # top-right point \n",
    "        x6, y6 = min(x2, x4), min(y2, y4) \n",
    "        # no intersection \n",
    "        if (x5 > x6 or y5 > y6) : \n",
    "            return None\n",
    "        # gives top-left point  \n",
    "        x7, y7 = x5, y6\n",
    "        # gives bottom-right point \n",
    "        x8, y8 = x6, y5\n",
    "        return x7,y7,x8,y8\n",
    "    \n",
    "    def contrastCorrectionFisheye(self, bmap):\n",
    "        '''This function aims to compensate the lens imperfect brightness distribution.\n",
    "        The lens is expected to have better brightness in the center, worse at the periphery.\n",
    "        \n",
    "        The brightness map is established with a Luxmeter. \n",
    "        The map consists in 5 points of elevation and 7 points of longitude, so 35 points total.\n",
    "        \n",
    "        The image projected is a uniform black background with a white circle of roughly 5 degrees radius.\n",
    "        The measurement is made in the center of the white circle.\n",
    "        The goal is to negate the effect of the rest of the screen (as it has been measured that a black\n",
    "        image's contrast is balanced over the full screen).\n",
    "        \n",
    "        On a greyscale, since we can not increase the white further (it can not get whiter), we have to decrease \n",
    "        the higher values.'''\n",
    "        return\n",
    "    \n",
    "    def getContrastCorrectionScreenValue(self, bmap):\n",
    "        '''This function aims to compensate the screen imperfect brightness distribution.\n",
    "        This is due to the spherical nature of the screen: rays bounce inside of it, causing the left-right parts to appear\n",
    "        brighter than the center (which faces a dark room) if a uniform white image is being displayed.\n",
    "        Note: it has to be applied after the contrastCorrectionFisheye, as the fisheye imperfection can not be negated.\n",
    "        \n",
    "        Because every different image projected will lead to different color and brightness distributions, the contrast \n",
    "        needs to be corrected image per image. That correction consists in the addition of a low-passed 'central symmetry' \n",
    "        reversed version of the image, by a certain amount.\n",
    "        That amount of correction needed is dependent on the screen (size and paint are its parameters - if you change\n",
    "        one of those, you will need to calibrate your screen again), that will be determined once with this function.\n",
    "        It also depends on every image used.\n",
    "        The central part faces a dark room, and therefore does not need any correction.\n",
    "        The other parts are affected by the screen segments facing them, displaying images. The goal is to negate the effect\n",
    "        on brightness of those pictures (but, obviously, without making them dark). This will be done by estimating the average\n",
    "        brightness on every facing sub-segments (1 degree wide), giving them weights following a gaussian curve, and \n",
    "        lowering the brightness of our final (non-facing) segment accordingly.\n",
    "        \n",
    "        The constraint is to achieve a 10% margin on the global contrast (so approximative it will be).\n",
    "        \n",
    "        The brightness map is established with a Luxmeter.\n",
    "        The map consists in 5 points of elevation and 7 points of longitude, so 35 points total.\n",
    "        \n",
    "        The image projected is a uniform white. This image has the maximal impact on contrast imperfections.\n",
    "        We will just apply the correction until it appears contrast perfect (measuring extreme points and center only\n",
    "        for rapid checking).\n",
    "        Knowing that a black image is contrast perfect without correction, we can start a curve.\n",
    "        \n",
    "        Assumptions: - the system can be sub-segmented\n",
    "                     - a rough discrete gaussian applies\n",
    "        '''\n",
    "        return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    im = cv2.imread('res/circle.png')\n",
    "    a=PanoImage(im, units = 'deg', size=[30,30], pos_angles=[0,-40]).stretch()\n",
    "\n",
    "    # xmap = np.loadtxt('res/xymappings/500x250/xmap.txt', dtype=np.float32)\n",
    "    # ymap = np.loadtxt('res/xymappings/500x250/ymap.txt', dtype=np.float32)\n",
    "    # b = a.toPano(xmap,ymap)\n",
    "\n",
    "    b = a.apply()\n",
    "\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(b,origin='lower')\n",
    "    cv2.imwrite('res/panocircle.png', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Imagedeform loop - Non vectorized version - more intelligible, slow\n",
    "x_old = 0\n",
    "for j in range(h):\n",
    "    y = int(posT[1] - float(h)/2 + j) #vector y\n",
    "    if 0 <= y < tex.shape[0]:\n",
    "        s = self._scalingFactor(self._pix2angles(np.array([0,y]),self.res)[1]) #vector s\n",
    "        if compress:\n",
    "            s = 1./s\n",
    "        for i in range(w):\n",
    "            x = int(s*(i - float(w)/2)) #vector x\n",
    "            if -wT <= x < wT:\n",
    "                if x == 0: #limit conditions for negative indexes\n",
    "                    xmap[j, x_old:] = i #list comprehensions\n",
    "                    ymap[j, x_old:] = j\n",
    "                else:\n",
    "                    xmap[j, x_old:x] = i\n",
    "                    ymap[j, x_old:x] = j\n",
    "\n",
    "                x_old = x\n",
    "'''\n",
    "%prun b = a.toPano(xmap,ymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
